#!/usr/bin/env python3
import sys
sys.dont_write_bytecode = True
"""
harness/sanitize - Automated sanitizer error fix loop

Runs make check-sanitize (ASan + UBSan), fixes errors one at a time with
escalation, commits on success, reverts on exhaustion, continues until
all pass or no progress is made.
"""

import argparse
import subprocess
import sys
import os
import re
import threading
import time
from datetime import datetime
from pathlib import Path

# Configuration
MAX_ATTEMPTS_PER_FILE = 3

# Escalation ladder: (model, thinking_budget, display_name)
ESCALATION_LADDER = {
    1: ("claude-sonnet-4-20250514", "10000", "sonnet:think"),
    2: ("claude-opus-4-20250514", "10000", "opus:think"),
    3: ("claude-opus-4-20250514", "128000", "opus:ultrathink"),
}

SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent.parent.parent
FIX_PROMPT_TEMPLATE = SCRIPT_DIR / "fix.prompt.md"
DEFAULT_TIMEOUT = 900

# Global flag to disable spinner (set by --no-spinner)
SPINNER_ENABLED = True


class Spinner:
    """Threaded spinner for long-running operations."""

    FRAMES = ["⠋", "⠙", "⠹", "⠸", "⠼", "⠴", "⠦", "⠧", "⠇", "⠏"]

    def __init__(self, message: str = ""):
        self.message = message
        self.running = False
        self.thread: threading.Thread | None = None
        self.start_time: float = 0

    def _spin(self) -> None:
        idx = 0
        while self.running:
            elapsed = int(time.time() - self.start_time)
            mins, secs = divmod(elapsed, 60)
            frame = self.FRAMES[idx % len(self.FRAMES)]
            sys.stdout.write(f"\r{frame} {self.message} [{mins:02d}:{secs:02d}]")
            sys.stdout.flush()
            idx += 1
            time.sleep(0.1)
        sys.stdout.write("\r" + " " * 60 + "\r")
        sys.stdout.flush()

    def start(self) -> None:
        if not SPINNER_ENABLED:
            return
        self.running = True
        self.start_time = time.time()
        self.thread = threading.Thread(target=self._spin, daemon=True)
        self.thread.start()

    def stop(self) -> None:
        self.running = False
        if self.thread:
            self.thread.join(timeout=1)


def log(msg: str) -> None:
    """Print timestamped log message."""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"{timestamp} | {'sanitize':10} | {msg}", flush=True)


def format_elapsed(seconds: float) -> str:
    """Format elapsed seconds as human-readable string."""
    hours, remainder = divmod(int(seconds), 3600)
    mins, secs = divmod(remainder, 60)
    if hours > 0:
        return f"{hours}h {mins}m {secs}s"
    elif mins > 0:
        return f"{mins}m {secs}s"
    else:
        return f"{secs}s"


def run_cmd(cmd: list[str], capture: bool = True, cwd: Path | None = None, timeout: int | None = None) -> tuple[int, str, str]:
    """Run a command and return (returncode, stdout, stderr)."""
    result = subprocess.run(
        cmd,
        capture_output=capture,
        text=True,
        cwd=cwd or PROJECT_ROOT,
        timeout=timeout,
    )
    return result.returncode, result.stdout or "", result.stderr or ""


def drop_test_databases() -> None:
    """Drop all test databases to ensure clean state."""
    log("Cleaning up test databases...")

    # Get list of test databases
    list_cmd = [
        "psql",
        "postgresql://ikigai:ikigai@localhost/postgres",
        "-t",  # tuples only (no headers/footers)
        "-c",
        "SELECT datname FROM pg_database WHERE datname LIKE 'ikigai_test_%';"
    ]

    code, stdout, stderr = run_cmd(list_cmd)
    if code != 0:
        log(f"Warning: Failed to list test databases: {stderr}")
        return

    # Parse database names from output
    db_names = [line.strip() for line in stdout.strip().split('\n') if line.strip()]

    if not db_names:
        log("No test databases found")
        return

    log(f"Found {len(db_names)} test database(s) to drop")

    # Drop each database
    for db_name in db_names:
        log(f"Dropping {db_name}...")
        drop_cmd = [
            "psql",
            "postgresql://ikigai:ikigai@localhost/postgres",
            "-c",
            f"DROP DATABASE IF EXISTS {db_name};"
        ]
        code, _, stderr = run_cmd(drop_cmd)
        if code != 0:
            log(f"Warning: Failed to drop {db_name}: {stderr}")
        else:
            log(f"Dropped {db_name}")


def run_make_sanitize() -> tuple[bool, str]:
    """Run make check-sanitize and return (success, output)."""
    log("Running make check-sanitize...")
    spinner = Spinner("Running make check-sanitize")
    spinner.start()
    code, stdout, stderr = run_cmd(["make", "check-sanitize", "MAKE_JOBS=1"], timeout=1800)
    spinner.stop()
    output = stdout + stderr
    return code == 0, output


def is_app_frame(file: str) -> bool:
    """Check if a file path is application code (not library)."""
    return file.startswith('src/') or file.startswith('tests/')


def is_library_frame(function: str, file: str) -> bool:
    """Check if a frame is from a library (libc, libasan, libtalloc)."""
    # Skip libc functions
    libc_funcs = {'free', 'malloc', 'calloc', 'realloc', 'aligned_alloc',
                  'posix_memalign', 'memalign', 'pvalloc', 'valloc',
                  '__interceptor_', 'vsnprintf_', 'vsprintf_', 'sprintf_'}
    for func in libc_funcs:
        if function.startswith(func) or func in function:
            return True

    # Skip libasan frames
    if '__asan' in function or '__sanitizer' in function:
        return True

    # Skip libtalloc frames
    if 'talloc' in file or 'talloc' in function:
        return True

    # Skip frames without source location
    if not file or file.startswith('/') or '(' in file:
        return True

    return False


def find_first_app_frame(lines: list[str], start: int, max_lines: int = 20) -> tuple[str, str, str]:
    """
    Find first application frame in a stack trace section.
    Returns (file, line, function) or ("", "", "") if not found.
    """
    # Pattern: #N 0xADDR in function_name file.c:123
    frame_pattern = re.compile(r'#\d+\s+0x[0-9a-f]+\s+in\s+(\S+)\s+(\S+):(\d+)')

    for i in range(start, min(start + max_lines, len(lines))):
        match = frame_pattern.search(lines[i])
        if match:
            function = match.group(1)
            file = match.group(2)
            line = match.group(3)

            if is_library_frame(function, file):
                continue

            if is_app_frame(file):
                return file, line, function

    return "", "", ""


def find_section_start(lines: list[str], start: int, pattern: str, max_lines: int = 50) -> int:
    """Find the start of a section matching pattern. Returns -1 if not found."""
    for i in range(start, min(start + max_lines, len(lines))):
        if pattern in lines[i]:
            return i
    return -1


def collect_stack_trace(lines: list[str], start: int, max_lines: int = 100) -> str:
    """Collect the full ASan output from error start until next error or end."""
    stack_lines = []
    for i in range(start, min(start + max_lines, len(lines))):
        line = lines[i]
        # Stop at next error or summary
        if i > start and '==ERROR:' in line:
            break
        if 'SUMMARY:' in line:
            stack_lines.append(line)
            break
        stack_lines.append(line)
    return '\n'.join(stack_lines)


def parse_failures(output: str) -> list[dict]:
    """
    Parse sanitizer output to extract errors.
    Returns list of dicts with all template variables.
    """
    failures = []
    seen_files = set()

    # AddressSanitizer pattern:
    # ==PID==ERROR: AddressSanitizer: error-type on address ...
    asan_error = re.compile(r'==\d+==ERROR: AddressSanitizer: (\S+)')

    # UndefinedBehaviorSanitizer pattern:
    # file.c:123:45: runtime error: description
    ubsan_pattern = re.compile(r'(\S+):(\d+):\d+:\s*runtime error:\s*(.+)')

    # LeakSanitizer pattern:
    # Direct leak of N byte(s) in M object(s) allocated from:
    lsan_error = re.compile(r'(Direct|Indirect) leak of \d+ byte')

    lines = output.split('\n')
    i = 0
    while i < len(lines):
        line = lines[i]

        # Check for ASan error
        asan_match = asan_error.search(line)
        if asan_match:
            error_type = asan_match.group(1).strip()

            # Extract message (the description after error type)
            message = line.split('AddressSanitizer:')[-1].strip() if 'AddressSanitizer:' in line else error_type

            # Collect full stack trace
            stack = collect_stack_trace(lines, i)

            # Find crash location (first app frame after error)
            file, line_num, _ = find_first_app_frame(lines, i + 1)

            # Find "freed by thread" section
            freed_start = find_section_start(lines, i, 'freed by thread')
            freed_file, freed_line, freed_function = "", "", ""
            if freed_start != -1:
                freed_file, freed_line, freed_function = find_first_app_frame(lines, freed_start + 1)

            # Find "previously allocated" section
            alloc_start = find_section_start(lines, i, 'previously allocated')
            allocated_file, allocated_line, allocated_function = "", "", ""
            if alloc_start != -1:
                allocated_file, allocated_line, allocated_function = find_first_app_frame(lines, alloc_start + 1)

            if file and file not in seen_files:
                seen_files.add(file)
                failures.append({
                    "file": file,
                    "line": line_num,
                    "error_type": error_type,
                    "message": message,
                    "freed_file": freed_file,
                    "freed_line": freed_line,
                    "freed_function": freed_function,
                    "allocated_file": allocated_file,
                    "allocated_line": allocated_line,
                    "allocated_function": allocated_function,
                    "stack": stack,
                })
            i += 1
            continue

        # Check for UBSan error
        ubsan_match = ubsan_pattern.search(line)
        if ubsan_match:
            file = ubsan_match.group(1)
            line_num = ubsan_match.group(2)
            message = ubsan_match.group(3)
            if file not in seen_files and is_app_frame(file):
                seen_files.add(file)
                failures.append({
                    "file": file,
                    "line": line_num,
                    "error_type": "undefined-behavior",
                    "message": message,
                    "freed_file": "",
                    "freed_line": "",
                    "freed_function": "",
                    "allocated_file": "",
                    "allocated_line": "",
                    "allocated_function": "",
                    "stack": "",
                })
            i += 1
            continue

        # Check for LSan error
        lsan_match = lsan_error.search(line)
        if lsan_match:
            leak_type = lsan_match.group(1)
            # Find allocation location
            file, line_num, function = find_first_app_frame(lines, i + 1)
            if file and file not in seen_files:
                seen_files.add(file)
                failures.append({
                    "file": file,
                    "line": line_num,
                    "error_type": f"{leak_type.lower()}-leak",
                    "message": f"{leak_type} memory leak",
                    "freed_file": "",
                    "freed_line": "",
                    "freed_function": "",
                    "allocated_file": file,
                    "allocated_line": line_num,
                    "allocated_function": function,
                    "stack": collect_stack_trace(lines, i),
                })
            i += 1
            continue

        i += 1

    return failures


def load_prompt_template() -> str:
    """Load the fix prompt template."""
    if not FIX_PROMPT_TEMPLATE.exists():
        log(f"ERROR: Missing {FIX_PROMPT_TEMPLATE}")
        sys.exit(1)
    return FIX_PROMPT_TEMPLATE.read_text()


def process_conditionals(template: str, variables: dict) -> str:
    """
    Process Handlebars-style {{#if var}}...{{/if}} conditionals.
    Includes block content if variable is truthy, removes it otherwise.
    """
    # Pattern: {{#if var_name}}...content...{{/if}}
    pattern = re.compile(r'\{\{#if\s+(\w+)\}\}(.*?)\{\{/if\}\}', re.DOTALL)

    def replacer(match: re.Match) -> str:
        var_name = match.group(1)
        content = match.group(2)
        if variables.get(var_name):
            return content
        return ""

    return pattern.sub(replacer, template)


def build_prompt(failure: dict, make_output: str) -> str:
    """Build the fix prompt from template."""
    template = load_prompt_template()

    # Build variables dict for conditional processing
    variables = {
        "file": failure["file"],
        "line": failure["line"],
        "error_type": failure["error_type"],
        "message": failure["message"],
        "freed_file": failure.get("freed_file", ""),
        "freed_line": failure.get("freed_line", ""),
        "freed_function": failure.get("freed_function", ""),
        "allocated_file": failure.get("allocated_file", ""),
        "allocated_line": failure.get("allocated_line", ""),
        "allocated_function": failure.get("allocated_function", ""),
        "stack": failure.get("stack", ""),
        "make_output": make_output[-6000:],
    }

    # Process conditionals first
    prompt = process_conditionals(template, variables)

    # Then substitute variables
    for key, value in variables.items():
        prompt = prompt.replace("{{" + key + "}}", value)

    return prompt


def invoke_claude(prompt: str, model: str, thinking_budget: str, model_name: str, timeout: int) -> tuple[bool, str]:
    """
    Invoke Claude CLI with the prompt via stdin.
    Returns (success, response).
    """
    import json
    import tempfile

    with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
        f.write(prompt)
        prompt_file = f.name

    spinner = Spinner(f"Waiting for {model_name}")
    try:
        cmd = f'cat "{prompt_file}" | claude -p - --model {model} --allowedTools "Read,Edit,Write,Bash,Glob,Grep" --output-format json --max-turns 30'
        env = os.environ.copy()
        env["MAX_THINKING_TOKENS"] = thinking_budget
        spinner.start()
        result = subprocess.run(
            cmd,
            shell=True,
            capture_output=True,
            text=True,
            cwd=PROJECT_ROOT,
            timeout=timeout,
            env=env,
        )
        spinner.stop()
        code = result.returncode
        stdout = result.stdout or ""
        stderr = result.stderr or ""
    except subprocess.TimeoutExpired:
        spinner.stop()
        return False, f"Timeout after {timeout} seconds"
    finally:
        Path(prompt_file).unlink(missing_ok=True)

    if code != 0:
        return False, stderr

    try:
        result = json.loads(stdout)
        return True, result.get("result", "")
    except json.JSONDecodeError:
        return True, stdout


def jj_get_modified_files() -> set[str]:
    """Get set of currently modified files."""
    code, stdout, _ = run_cmd(["jj", "diff", "--summary"])
    files = set()
    for line in stdout.strip().split('\n'):
        if line.strip():
            parts = line.split(None, 1)
            if len(parts) == 2:
                files.add(parts[1])
    return files


def jj_commit(failure: dict, model_name: str, attempt: int, files_before: set[str]) -> bool:
    """Commit only files that changed during fix attempt."""
    files_after = jj_get_modified_files()
    new_changes = files_after - files_before

    if not new_changes:
        return False

    file_name = Path(failure["file"]).name
    error_type = failure["error_type"].split(':')[0]  # ASan, UBSan, or LSan
    msg = f"fix: {error_type} error in {file_name}\n\nharness/sanitize | {model_name} | attempt {attempt}"

    code, _, _ = run_cmd(["jj", "commit", "-m", msg])
    return code == 0


def jj_revert(files_before: set[str] | None = None) -> None:
    """Revert changes made during fix attempt."""
    if files_before is not None:
        files_after = jj_get_modified_files()
        new_changes = files_after - files_before
        if new_changes:
            log("Reverting uncommitted changes...")
            for f in new_changes:
                run_cmd(["jj", "restore", f])
    else:
        if jj_get_modified_files():
            log("Reverting uncommitted changes...")
            run_cmd(["jj", "restore"])


def try_fix_file(failure: dict, make_output: str, timeout: int) -> bool:
    """
    Attempt to fix a sanitizer error.
    Returns True if fixed, False if exhausted attempts.
    """
    file = failure["file"]

    files_before = jj_get_modified_files()

    for attempt in range(1, MAX_ATTEMPTS_PER_FILE + 1):
        model, thinking_budget, model_name = ESCALATION_LADDER[attempt]

        log(f"Trying {model_name} (attempt {attempt}/{MAX_ATTEMPTS_PER_FILE})")

        prompt = build_prompt(failure, make_output)
        success, response = invoke_claude(prompt, model, thinking_budget, model_name, timeout)

        if not success:
            log(f"{model_name} invocation FAILED: {response[:200]}")
            continue

        # Verify the fix
        check_passed, _ = run_make_sanitize()

        if check_passed:
            log(f"{model_name} SUCCESS")
            jj_commit(failure, model_name, attempt, files_before)
            return True
        else:
            log(f"{model_name} FAILED (sanitizer errors remain)")

    # Exhausted all attempts
    log(f"SKIPPED - exhausted {MAX_ATTEMPTS_PER_FILE} attempts")
    jj_revert(files_before)
    return False


def main() -> int:
    """Main entry point."""
    start_time = time.time()
    parser = argparse.ArgumentParser(description="Automated sanitizer error fix loop")
    parser.add_argument("--dry-run", action="store_true",
                        help="Identify sanitizer errors without fixing them")
    parser.add_argument("--no-spinner", action="store_true",
                        help="Disable progress spinner (for non-interactive use)")
    parser.add_argument("--time-out", type=int, default=DEFAULT_TIMEOUT,
                        help=f"Timeout in seconds for each LLM invocation (default: {DEFAULT_TIMEOUT})")
    args = parser.parse_args()

    global SPINNER_ENABLED
    if args.no_spinner:
        SPINNER_ENABLED = False

    opts = []
    if args.dry_run:
        opts.append("dry-run")
    if args.time_out != DEFAULT_TIMEOUT:
        opts.append(f"timeout={args.time_out}s")
    log("Starting" + (f" ({', '.join(opts)})" if opts else ""))
    os.chdir(PROJECT_ROOT)

    # Clean build to start fresh
    log("Running make clean...")
    spinner = Spinner("Running make clean")
    spinner.start()
    run_cmd(["make", "clean"])
    spinner.stop()

    # Drop test databases
    drop_test_databases()

    # Run sanitizer check
    success, output = run_make_sanitize()

    if success:
        log(f"All sanitizer checks passed! (elapsed: {format_elapsed(time.time() - start_time)})")
        return 0

    failures = parse_failures(output)

    if not failures:
        log("make check-sanitize failed but couldn't parse failures")
        log("Output tail:")
        for line in output.split('\n')[-30:]:
            log(f"  {line}")
        log(f"Completed with errors (elapsed: {format_elapsed(time.time() - start_time)})")
        return 1

    log(f"Found {len(failures)} sanitizer errors")

    # Dry-run: just list failures and exit
    if args.dry_run:
        log("Errors needing fixes:")
        for failure in failures:
            log(f"  - {failure['file']}:{failure['line']} - {failure['error_type']}")
        log(f"Completed (elapsed: {format_elapsed(time.time() - start_time)})")
        return 0

    pass_num = 0

    while True:
        pass_num += 1
        log(f"=== Pass {pass_num} ===")

        if pass_num > 1:
            # Re-run check for subsequent passes
            success, output = run_make_sanitize()

            if success:
                log(f"All sanitizer checks passed! (elapsed: {format_elapsed(time.time() - start_time)})")
                return 0

            failures = parse_failures(output)

            if not failures:
                log("make check-sanitize failed but couldn't parse failures")
                log("Output tail:")
                for line in output.split('\n')[-30:]:
                    log(f"  {line}")
                log(f"Completed with errors (elapsed: {format_elapsed(time.time() - start_time)})")
                return 1

            log(f"Found {len(failures)} sanitizer errors")

        fixed_count = 0
        skipped = []
        file_times: list[float] = []

        for i, failure in enumerate(failures, 1):
            file = failure["file"]
            error = failure["error_type"]
            log(f"[file {i}/{len(failures)}] {file}:{failure['line']} - {error}")

            file_start = time.time()
            if try_fix_file(failure, output, args.time_out):
                fixed_count += 1
            else:
                skipped.append(f"{file}:{failure['line']}")

            file_elapsed = time.time() - file_start
            file_times.append(file_elapsed)
            avg_time = sum(file_times) / len(file_times)
            remaining = len(failures) - i
            eta = avg_time * remaining
            log(f"elapsed: {format_elapsed(file_elapsed)} | ETA: {format_elapsed(eta)}")

        log(f"Pass {pass_num} complete: {fixed_count} fixed, {len(skipped)} skipped")

        if fixed_count > 0 and len(skipped) == 0:
            log(f"All failures fixed! (elapsed: {format_elapsed(time.time() - start_time)})")
            return 0

        if fixed_count == 0:
            log("No progress made. Stopping.")
            if skipped:
                log("Skipped errors:")
                for f in skipped:
                    log(f"  - {f}")
            log(f"Completed with failures (elapsed: {format_elapsed(time.time() - start_time)})")
            return 1


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        sys.exit(130)
