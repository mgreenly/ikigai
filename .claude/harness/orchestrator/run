#!/usr/bin/env ruby
# frozen_string_literal: true

#
# harness/orchestrator/run - Pipeline orchestrator for concurrent goal execution
#
# Usage: orchestrator --max N [--model MODEL] [--reasoning LEVEL] [--duration DURATION]
#
# Picks up queued goals, spawns ralphs in isolated clones, collects results,
# creates PRs on success, retries on failure, and notifies on spot-check.
#
# Arguments:
#   --max N            Maximum concurrent ralphs (required)
#   --model MODEL      Model for ralphs: haiku, sonnet, opus (default: sonnet)
#   --reasoning LEVEL  Reasoning level: none, low, med, high (default: med)
#   --duration DUR     Time budget per ralph (e.g., 4h, 200m)
#
# Exit code: 0 on clean shutdown, 130 on interrupt
#

require 'json'
require 'optparse'
require 'fileutils'
require 'set'
require 'open3'

SCRIPT_DIR = File.dirname(File.realpath(__FILE__))
PROJECT_ROOT = File.expand_path('../../..', SCRIPT_DIR)
RALPHS_DIR = File.join(PROJECT_ROOT, '.ralphs')
RALPH_SCRIPT = File.join(SCRIPT_DIR, '..', 'ralph', 'run')
NOTIFY_SCRIPT = File.join(SCRIPT_DIR, '..', 'notify', 'run')
GOAL_LIST_SCRIPT = File.join(SCRIPT_DIR, '..', 'goal-list', 'run')
GOAL_GET_SCRIPT = File.join(SCRIPT_DIR, '..', 'goal-get', 'run')
STORY_TRY_CLOSE_SCRIPT = File.join(SCRIPT_DIR, '..', 'story-try-close', 'run')
MAX_RETRIES = 3
LOG_DIR = File.join(PROJECT_ROOT, '.pipeline', 'cache')
LOG_FILE = File.join(LOG_DIR, 'orchestrator.log')

def init_log
  FileUtils.mkdir_p(LOG_DIR)
  @log_file = File.open(LOG_FILE, 'w')
end

def log(message)
  timestamp = Time.now.strftime('%Y-%m-%d %H:%M:%S')
  line = "[#{timestamp}] #{message}"
  puts line
  $stdout.flush
  @log_file.puts(line)
  @log_file.flush
end

def parse_depends(body)
  return [] unless body
  match = body.match(/^Depends:\s*(.+)$/i)
  return [] unless match
  match[1].scan(/#(\d+)/).flatten.map(&:to_i)
end

def dependencies_met?(depends_on)
  return true if depends_on.empty?
  depends_on.all? do |dep_number|
    result = run_script(GOAL_GET_SCRIPT, dep_number.to_s)
    result && result['ok'] && result['labels']&.include?('goal:done')
  end
end

def run_script(script, *args)
  cmd = [script] + args
  stdout = IO.popen(cmd, err: '/dev/null', &:read)
  return nil unless $?.exitstatus == 0

  JSON.parse(stdout)
rescue JSON::ParserError
  nil
end

def get_remote_url
  output = IO.popen(%w[jj git remote list], chdir: PROJECT_ROOT, err: '/dev/null', &:read)
  return nil unless $?.exitstatus == 0

  output.each_line do |line|
    parts = line.strip.split(/\s+/)
    return parts[1] if parts[0] == 'origin' && parts[1]
  end
  nil
end

def parse_org_repo(remote_url)
  # Handle both git@github.com:org/repo.git and https://github.com/org/repo.git
  if remote_url =~ %r{^git@github\.com:([^/]+)/(.+?)(?:\.git)?$}
    [$1, $2.sub(/\.git$/, '')]
  elsif remote_url =~ %r{^https://github\.com/([^/]+)/(.+?)(?:\.git)?$}
    [$1, $2.sub(/\.git$/, '')]
  else
    nil
  end
end

def transition_label(number, from_label, to_label)
  system('gh', 'issue', 'edit', number.to_s,
         '--remove-label', from_label,
         '--add-label', to_label,
         out: '/dev/null', err: '/dev/null')
end

def clone_repo(remote_url, org, repo, number)
  dest = File.join(RALPHS_DIR, org, repo, number.to_s)
  FileUtils.mkdir_p(File.dirname(dest))
  system('git', 'clone', '--quiet', remote_url, dest, out: '/dev/null', err: '/dev/null')
  return nil unless $?.exitstatus == 0

  # Initialize jj so ralph's commits work inside the clone
  system('jj', 'git', 'init', chdir: dest, out: '/dev/null', err: '/dev/null')
  dest
end

def delete_clone(org, repo, number)
  dest = File.join(RALPHS_DIR, org, repo, number.to_s)
  FileUtils.rm_rf(dest) if Dir.exist?(dest)
end

def create_pr_from_clone(number, title, clone_dir)
  branch = "goal-#{number}"

  # Commit any uncommitted working copy changes
  system('jj', 'commit', '-m', "Goal ##{number}: #{title}",
         chdir: clone_dir, out: '/dev/null', err: '/dev/null')

  # Check if there are commits beyond main
  jj_log = IO.popen(['jj', 'log', '-r', 'main@origin..@-', '--no-graph', '-T', 'change_id.short()'],
                     chdir: clone_dir, err: '/dev/null', &:read)
  if jj_log.strip.empty?
    log "Goal ##{number} no changes to push, skipping PR"
    return nil
  end

  # Create bookmark on last commit, track, and push
  system('jj', 'bookmark', 'create', branch, '-r', '@-',
         chdir: clone_dir, out: '/dev/null', err: '/dev/null')
  system('jj', 'bookmark', 'track', "#{branch}@origin",
         chdir: clone_dir, out: '/dev/null', err: '/dev/null')
  system('jj', 'git', 'push', '--bookmark', branch,
         chdir: clone_dir, out: '/dev/null', err: '/dev/null')

  unless $?.exitstatus == 0
    log "Goal ##{number} failed to push"
    return nil
  end

  # Create PR
  body = "Closes ##{number}"
  pr_output = IO.popen(
    ['gh', 'pr', 'create', '--title', title, '--body', body, '--head', branch],
    chdir: clone_dir, err: '/dev/null', &:read
  )

  if $?.exitstatus == 0
    pr_num = pr_output.strip.split('/').last
    pr_num
  else
    log "Goal ##{number} failed to create PR"
    nil
  end
end

def notify(title, message)
  payload = JSON.generate(title: title, message: message)
  IO.popen(NOTIFY_SCRIPT, 'r+') do |io|
    io.write(payload)
    io.close_write
    io.read
  end
rescue StandardError
  # Notification failure is non-fatal
end

def format_elapsed(seconds)
  hours, remainder = seconds.divmod(3600)
  mins, secs = remainder.divmod(60)
  if hours > 0
    "#{hours}h#{mins}m#{secs}s"
  elsif mins > 0
    "#{mins}m#{secs}s"
  else
    "#{secs}s"
  end
end

def main(options)
  init_log

  max_slots = options[:max]
  model = options[:model]
  reasoning = options[:reasoning]
  duration = options[:duration]

  remote_url = get_remote_url
  unless remote_url
    $stderr.puts 'Error: could not determine origin remote URL'
    exit 1
  end

  org_repo = parse_org_repo(remote_url)
  unless org_repo
    $stderr.puts 'Error: could not parse org/repo from remote URL'
    exit 1
  end
  org, repo = org_repo

  log "Starting orchestrator (max #{max_slots} ralphs)"
  log "Remote: #{remote_url}"
  log "Repo: #{org}/#{repo}"
  log "Model: #{model} | Reasoning: #{reasoning} | Duration: #{duration || 'unlimited'}"

  # State tracking
  running = {}      # pid => {number:, title:, spot_check:, dir:, started_at:, stream_thread:, wait_thread:}
  retries = Hash.new(0)  # goal_number => retry count
  attempted = Set.new  # goal_number => attempted at least once this session
  last_queued_count = nil
  last_running_count = nil
  @shutting_down = false

  # Ctrl+C handler
  trap('INT') do
    @shutting_down = true
  end

  loop do
    # ── Shutdown ──
    if @shutting_down
      log 'Shutting down...'
      running.each do |pid, info|
        Process.kill('INT', pid) rescue nil
        Process.wait(pid) rescue nil
        info[:stream_thread]&.join rescue nil
        transition_label(info[:number], 'goal:running', 'goal:queued')
        log "Goal ##{info[:number]} → re-queued (was running)"
        delete_clone(org, repo, info[:number])
        log "Cleaned up .ralphs/#{org}/#{repo}/#{info[:number]}/"
      end
      log 'Done'
      break
    end

    # ── Collect finished ralphs ──
    finished = []
    running.each do |pid, info|
      unless info[:wait_thread].alive?
        status = info[:wait_thread].value
        finished << [pid, status]
      end
    end

    finished.each do |pid, status|
      info = running.delete(pid)
      number = info[:number]
      elapsed = format_elapsed((Time.now - info[:started_at]).to_i)

      # Wait for stream thread to finish writing all output
      info[:stream_thread]&.join

      if status.exitstatus == 0
        log "Goal ##{number} ralph finished (exit 0, #{elapsed})"

        if info[:spot_check]
          # Needs human spot-check
          transition_label(number, 'goal:running', 'goal:spot-check')
          notify("Goal ##{number} needs spot-check", "\"#{info[:title]}\" completed in #{elapsed}")
          log "Goal ##{number} → spot-check"
          # Keep clone for human review
        else
          # Success — create PR
          pr_num = create_pr_from_clone(number, info[:title], info[:dir])
          if pr_num
            log "Goal ##{number} PR created → ##{pr_num}"
            if system('gh', 'pr', 'merge', '--auto', '--squash', pr_num.to_s, out: '/dev/null', err: '/dev/null')
              log "Goal ##{number} auto-merge enabled on PR ##{pr_num}"
            else
              log "Goal ##{number} auto-merge failed on PR ##{pr_num} (non-fatal)"
            end
          end
          transition_label(number, 'goal:running', 'goal:done')
          system(STORY_TRY_CLOSE_SCRIPT, number.to_s, out: '/dev/null', err: '/dev/null')
          log "Goal ##{number} → done"
          delete_clone(org, repo, number)
        end
      else
        log "Goal ##{number} ralph finished (exit #{status.exitstatus}, #{elapsed})"
        delete_clone(org, repo, number)
        log "Goal ##{number} cleaned up .ralphs/#{org}/#{repo}/#{number}/"
        retries[number] += 1

        if retries[number] > MAX_RETRIES
          transition_label(number, 'goal:running', 'goal:stuck')
          log "Goal ##{number} → stuck (#{retries[number]} retries exhausted)"
          notify("Goal ##{number} stuck", "\"#{info[:title]}\" failed #{retries[number]} times")
        else
          transition_label(number, 'goal:running', 'goal:queued')
          log "Goal ##{number} failed → re-queued (retry #{retries[number]}/#{MAX_RETRIES})"
        end
      end
    end

    # ── Clean up approved spot-check clones ──
    # Traverse .ralphs/<org>/<repo>/<number>/ structure
    Dir.glob(File.join(RALPHS_DIR, '*', '*', '*')).each do |clone_path|
      next unless File.directory?(clone_path)

      number = File.basename(clone_path).to_i
      next if number == 0  # Skip non-numeric directories

      # Don't delete clones for currently running goals
      next if running.values.any? { |info| info[:number] == number }

      # Check if goal is no longer in spot-check state
      goal_data = run_script(GOAL_GET_SCRIPT, number.to_s)
      next unless goal_data && goal_data['ok']

      labels = goal_data['labels'] || []

      # If not in spot-check, delete the clone
      unless labels.include?('goal:spot-check')
        delete_clone(org, repo, number)
        log "Cleaned up .ralphs/#{org}/#{repo}/#{number}/ (goal no longer in spot-check)"
      end
    end

    # ── Fill open slots ──
    result = run_script(GOAL_LIST_SCRIPT, 'queued')
    queued = (result && result['ok'] && result['items']) || []
    queued_count = queued.size
    running_count = running.size

    if queued_count != last_queued_count || running_count != last_running_count
      log "#{queued_count} queued, #{running_count} running"
      last_queued_count = queued_count
      last_running_count = running_count
    end

    available_slots = max_slots - running.size

    if available_slots > 0
      # Sort by issue number ascending (FIFO)
      queued.sort_by! { |g| g['number'] }

      # Partition into untried and retried goals for fairness
      untried = queued.reject { |g| attempted.include?(g['number']) }
      retried = queued.select { |g| attempted.include?(g['number']) }

      # Dispatch untried goals first, then retried
      candidates = (untried + retried).first(available_slots)

      candidates.each do |goal|
        number = goal['number']
        title = goal['title']
        spot_check = goal['spot_check']

        # Check dependencies before cloning
        goal_data = run_script(GOAL_GET_SCRIPT, number.to_s)
        unless goal_data && goal_data['ok']
          log "Goal ##{number} failed to fetch goal body, skipping"
          next
        end

        depends_on = parse_depends(goal_data['body'])
        unless dependencies_met?(depends_on)
          log "Goal ##{number} waiting on dependencies: #{depends_on.map { |n| "##{n}" }.join(', ')}"
          next
        end

        # Transition to running
        transition_label(number, 'goal:queued', 'goal:running')
        log "Goal ##{number} \"#{title}\" → running (slot #{running.size + 1}/#{max_slots})"

        # Clone
        clone_dir = clone_repo(remote_url, org, repo, number)
        unless clone_dir
          log "Goal ##{number} clone failed, re-queuing"
          transition_label(number, 'goal:running', 'goal:queued')
          next
        end
        log "Goal ##{number} cloned to .ralphs/#{org}/#{repo}/#{number}/"

        # Write goal body into .pipeline/cache/ (gitignored, keeps runtime files out of commits)
        cache_dir = File.join(clone_dir, '.pipeline', 'cache')
        FileUtils.mkdir_p(cache_dir)
        goal_file = File.join(cache_dir, 'goal.md')
        File.write(goal_file, goal_data['body'])

        # Spawn ralph with real-time log streaming
        ralph_log = File.join(cache_dir, 'ralph.log')
        ralph_args = [
          RALPH_SCRIPT,
          "--goal=.pipeline/cache/goal.md",
          '--log-mode',
          '--no-pull-request',
          "--model=#{model}",
          "--reasoning=#{reasoning}"
        ]
        ralph_args << "--duration=#{duration}" if duration

        # Use Open3.popen2e to stream output with proper wait_thread handling
        log_file = File.open(ralph_log, 'w')
        stdin, stdout_and_stderr, wait_thread = Open3.popen2e(*ralph_args, chdir: clone_dir)
        stdin.close  # We don't need stdin
        pid = wait_thread.pid

        # Stream output in a background thread
        stream_thread = Thread.new do
          begin
            stdout_and_stderr.each_line do |line|
              log_file.puts(line)
              log_file.flush
            end
          ensure
            stdout_and_stderr.close
            log_file.close
          end
        end

        log "Goal ##{number} ralph started (pid #{pid}, log: .ralphs/#{org}/#{repo}/#{number}/.pipeline/cache/ralph.log)"

        # Mark this goal as attempted for fairness tracking
        attempted.add(number)

        running[pid] = {
          number: number,
          title: title,
          spot_check: spot_check,
          dir: clone_dir,
          started_at: Time.now,
          stream_thread: stream_thread,
          wait_thread: wait_thread
        }
      end
    end

    # ── Sleep ──
    sleep 5
  end
end

# ─────────────────────────────────────────────────────────────
# CLI
# ─────────────────────────────────────────────────────────────

options = {
  model: 'sonnet',
  reasoning: 'med'
}

OptionParser.new do |opts|
  opts.banner = <<~BANNER
    Orchestrator - Pipeline coordinator for concurrent goal execution

    Usage: orchestrator --max N [--model MODEL] [--reasoning LEVEL] [--duration DURATION]
  BANNER

  opts.on('--max=N', Integer, 'Maximum concurrent ralphs (required)') do |n|
    options[:max] = n
  end

  opts.on('--model=MODEL', %w[haiku sonnet opus], 'Model: haiku, sonnet, opus (default: sonnet)') do |m|
    options[:model] = m
  end

  opts.on('--reasoning=LEVEL', %w[none low med high], 'Reasoning: none, low, med, high (default: med)') do |r|
    options[:reasoning] = r
  end

  opts.on('--duration=DURATION', 'Time budget per ralph (e.g., 4h, 200m)') do |d|
    options[:duration] = d
  end

  opts.on('-h', '--help', 'Show this help') do
    puts opts
    exit
  end
end.parse!

if options[:max].nil? || options[:max] < 1
  $stderr.puts 'Error: --max=N is required (must be >= 1)'
  $stderr.puts 'Usage: orchestrator --max N [--model MODEL] [--reasoning LEVEL] [--duration DURATION]'
  exit 1
end

if __FILE__ == $PROGRAM_NAME
  begin
    main(options)
  rescue Interrupt
    exit 130
  end
end
