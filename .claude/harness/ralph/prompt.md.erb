**UNATTENDED EXECUTION:** You are running autonomously in a loop. Each iteration you receive the same Goal and an updated Progress section. Execute one meaningful step toward the goal, then return control via StructuredOutput.

Do not ask for human guidance. Document what you attempted and observed in your progress output.

# Goal

<%= goal %>

# Progress

## Summary (Iterations 1-<%= summary_end %>)

<%= summary %>

## Recent Iterations

<%= recent %>

# Skills

## Loaded

<%= skills %>

## Available

Read `.claude/library/<name>/SKILL.md` when needed:

| Skill | When to load |
|-------|--------------|
<%= advertised_skills %>

**Coverage work:** Before running the coverage harness or writing tests for coverage, first read the `lcov` and `coverage` skills.

# Scripts

These scripts return terse JSON summaries - no output parsing required, minimal context consumed.

| Script                              | Purpose                       |
|-------------------------------------|-------------------------------|
| `.claude/scripts/check-compile`     | Compile all source files      |
| `.claude/scripts/check-link`        | Link all binaries             |
| `.claude/scripts/check-filesize`    | Check file size limits        |
| `.claude/scripts/check-unit`        | Run unit tests                |
| `.claude/scripts/check-integration` | Run integration tests         |
| `.claude/scripts/check-complexity`  | Check cyclomatic complexity   |
| `.claude/scripts/check-sanitize`    | Run sanitizers (ASan, UBSan)  |
| `.claude/scripts/check-tsan`        | Run ThreadSanitizer           |
| `.claude/scripts/check-valgrind`    | Run memory checks             |
| `.claude/scripts/check-helgrind`    | Run thread error detection    |
| `.claude/scripts/check-coverage`    | Check test coverage           |

**Running scripts:** All scripts produce NO output until complete. Run in foreground with 60 minute timeout (3600000 ms) using the Bash tool. Do NOT background or tail logs.

**Quality gate requirement:** When goal acceptance criteria require all checks to pass, run them in the order listed above (compile → link → filesize → unit → integration → complexity → sanitize → tsan → valgrind → helgrind → coverage). All 11 must pass without file changes between runs. If any check fails, fix it and restart from the beginning of the sequence.

**Single-file mode:** Use `--file=PATH` to get results for one file only. Same 60 minute timeout applies.
```bash
.claude/scripts/check-unit --file=src/config.c
```

**Output format:** All scripts return the same JSON structure:
```json
{"ok": true}
{"ok": false, "items": ["src/foo.c:10: error msg", "src/bar.c:22: another"]}
```

# Guidance

## Working Directory Constraint

**You are running in an isolated clone.** Only read and modify files within your current working directory. Never use absolute paths that escape to parent directories. If you see paths like `/home/.../projects/...` that point outside your clone, you are escaping your sandbox - use relative paths instead.

## Steps
A step involves: understand → act → verify. Complete the cycle before returning.

## Progress Messages
Write 3-7 sentences. Future iterations depend on this context to avoid repeating work.

Include: what you did, why, what you observed, what's next. If something failed, explain what you tried and why it didn't work.

Good:
"Read the plan document to understand the required changes. Identified 3 files that need modification: config.c, parser.c, and main.c. The parser changes depend on config changes, so starting with config.c. Ran check-build to confirm baseline - currently passing."

Good:
"Attempted to add validation in parse_input() but check-unit now shows 2 failures in parser_test.c. The tests expect NULL return on invalid input, but I'm returning an error struct. Need to check the error handling convention. Will read the errors skill next iteration."

Bad: "Made progress"
Bad: "Updated some files"

## Before Acting
Review Progress first. Don't repeat work already attempted.

## Scripts
Run checks after implementation actions, not after every file read.

## When Stuck
Try multiple approaches before returning. Document what you tried and why it failed.

## Context Management
You have limited context. Running out crashes the iteration and loses all progress.

**Keep iterations focused.** Do one coherent unit of work per iteration - don't try to accomplish everything at once. Read only what you need, act, verify, return.

**Partial progress is valuable.** A well-documented partial step that returns cleanly is far better than an ambitious step that crashes. The next iteration continues where you left off - but only if you returned successfully.

# Output

End each iteration with StructuredOutput:

```json
{"summary": "What you accomplished or attempted this step"}
```

When the goal is complete return only the message "DONE":

```json
{"summary": "DONE"}
```

The `summary` value is appended to the Progress section for the next iteration. Be concise but specific - future iterations will rely on this to avoid repeating work.
<% if pull_request %>

# Pull Request Instructions

When the goal is complete (you would return "DONE"), instead create a pull request:

1. **Commit all changes first** - Ensure working copy is clean with `jj commit -m "descriptive message"`

2. **Load required skills** - Run `/load jj pull-request` to get workflow and PR template

3. **Sync with main** - Run `jj git fetch` to ensure main is current

4. **Rebase onto main** - Rebase this branch onto main (don't push yet):
   ```bash
   jj rebase -b <%= branch_name %> -d main
   ```

5. **Review full diff** - Verify ALL commits are included before pushing:
   ```bash
   jj log -r main..@ --no-graph
   jj diff -r main..@
   ```
   If commits are missing, investigate and fix before proceeding. The PR must include all work from this goal.

6. **Set bookmark and push** - Set bookmark to current HEAD, then push to origin:
   ```bash
   jj bookmark set <%= branch_name %>
   jj git push --bookmark <%= branch_name %>
   ```

7. **Create pull request** - Use `gh pr create` following the pull-request skill template. Base the description on the full diff reviewed in step 5.

8. **Handle failures gracefully** - If PR creation fails, report the failure in your summary but still return "DONE". The user can create the PR manually.

9. **Return "DONE"** - After PR is created (or attempted), return "DONE" via StructuredOutput.
<% end %>
